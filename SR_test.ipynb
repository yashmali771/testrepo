{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5cb7d2fb-176d-4f60-a43b-fd38629e329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56821df0-35a2-46e1-b5f8-a5a3865299aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "srgan_model = load_model('tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b243131b-4243-497c-ba50-70e9421d9d77",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(input_image_path)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Preprocess the input image (resize and normalize)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(input_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# Convert to RGB color space\u001b[39;00m\n\u001b[0;32m      6\u001b[0m input_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(input_image, (srgan_model\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m], srgan_model\u001b[38;5;241m.\u001b[39minput_shape[\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m      7\u001b[0m input_image \u001b[38;5;241m=\u001b[39m input_image \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Normalize pixel values to [0, 1]\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "input_image_path = 'https://img.wattpad.com/cover/274924655-256-k589010.jpg'\n",
    "input_image = cv2.imread(input_image_path)\n",
    "\n",
    "# Preprocess the input image (resize and normalize)\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)  # Convert to RGB color space\n",
    "input_image = cv2.resize(input_image, (srgan_model.input_shape[1], srgan_model.input_shape[2]))\n",
    "input_image = input_image / 255.0  # Normalize pixel values to [0, 1]\n",
    "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6930729d-0f96-417c-9bdd-38bde580c8bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m enhanced_image \u001b[38;5;241m=\u001b[39m srgan_model\u001b[38;5;241m.\u001b[39mpredict(input_image)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1105\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1102\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[1;32m-> 1105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle input: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1107\u001b[0m             _type_name(x), _type_name(y)\n\u001b[0;32m   1108\u001b[0m         )\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[0;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[0;32m   1115\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "enhanced_image = srgan_model.predict(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fce326ca-82df-468a-9020-33eeff97126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_image = np.clip(enhanced_image[0], 0.0, 1.0) * 255.0\n",
    "enhanced_image = enhanced_image.astype(np.uint8)\n",
    "\n",
    "enhanced_image = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Save or display the enhanced image\n",
    "output_image_path = 'enhanced_image.jpg'\n",
    "# cv2.imwrite(output_image_path, enhanced_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "52533b81-11d1-4715-b8db-2f553568535c",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menhanced_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(a, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "a = cv2.imread('enhanced_image.jpg')\n",
    "a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e65d6b28-8080-4816-9ac9-0ebb61b36ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1 into shape (100,100,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m5\u001b[39m)) \n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m121\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m input_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(input_image, (\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(input_image)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m122\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m'\u001b[39m, newshape, order\u001b[38;5;241m=\u001b[39morder)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(asarray(obj), method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (100,100,3)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5)) \n",
    "plt.subplot(121)\n",
    "input_image = np.reshape(input_image, (100,100,3))\n",
    "plt.imshow(input_image)\n",
    "plt.subplot(122)\n",
    "# a = np.reshape(a, (400,400,3))\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35ef79-e7dc-4e9d-bb15-154b801e054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = cv2.resize(a, (srgan_model.input_shape[1], srgan_model.input_shape[2]))\n",
    "a = a / 255.0  # Normalize pixel values to [0, 1]\n",
    "a = np.expand_dims(a, axis=0)  # Add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2c87f-ebcd-4e0e-8f85-19c5cbe607df",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = srgan_model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ca1a8-e9c0-4c79-aa4d-72e538d9e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e2 = np.clip(e2[0], 0.0, 1.0) * 255.0\n",
    "e2 = e2.astype(np.uint8)\n",
    "cv2.imwrite(\"e2.jpg\", e2)\n",
    "b = cv2.imread('e2.jpg')\n",
    "b = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462b308-f22a-4b60-865f-1b6318a711a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5)) \n",
    "plt.subplot(121)\n",
    "input_image = np.reshape(input_image, (100,100,3))\n",
    "plt.imshow(input_image)\n",
    "plt.subplot(122)\n",
    "b = cv2.cvtColor(b, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d4ac608-7685-4bca-b1be-c4e0e3569cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = cv2.cvtColor(b,cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(\"results/pic.jpg\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5ddb2f40-43dd-4bdb-9cdd-3d29923958c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix_operations.cpp:67: error: (-215:Assertion failed) src[i].dims <= 2 && src[i].rows == src[0].rows && src[i].type() == src[0].type() in function 'cv::hconcat'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m image1 \u001b[38;5;241m=\u001b[39m input_image\n\u001b[0;32m      5\u001b[0m image2 \u001b[38;5;241m=\u001b[39mb \n\u001b[1;32m----> 6\u001b[0m concatenated_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mhconcat([image1, image2])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Save the resulting image\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcatenated_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, concatenated_image)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\matrix_operations.cpp:67: error: (-215:Assertion failed) src[i].dims <= 2 && src[i].rows == src[0].rows && src[i].type() == src[0].type() in function 'cv::hconcat'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73713c-8478-46a6-bfb3-eead8202569b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
